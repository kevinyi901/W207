{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBGpTcLsHB31"
      },
      "source": [
        "# **UCB W207 Final Project**\n",
        "\n",
        "## Using Machine Learning to Predict Travel Review Sentiment\n",
        "\n",
        "Section 3\n",
        "18 April 2025\n",
        "\n",
        "Kevin Yi, Kritin Nandish, Thrishna Bhandari, Patrick Abousleiman\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4N-CcyI9k2t"
      },
      "source": [
        "# Introduction: Problem Motivation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVRaG5k5vmcZ"
      },
      "source": [
        "## Outline for our notebook\n",
        "\n",
        "* Section 1: We import the data, the source being the Tripadvisor Hotel Review Dataset file with 20K reviews, from the publication: Alam, M. H., Ryu, W.-J., Lee, S., 2016. Joint multi-grain topic senti- ment: modeling semantic aspects for online reviews. Information Sci- ences 339, 206â€“223.\n",
        "* Section 2: We undertake feature engineering and data cleaning. We did xyz....\n",
        "* Section 3: Simple exploratory data analysis is performed. We found xyx...\n",
        "* Section 4:  We build several models, starting from the baseline model, logistic regression with one hot encoding, logistic regression with embedding, and multilayer RNN.\n",
        "* Section 5:  Conclusions from our analysis. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UITwLvKdw-El"
      },
      "source": [
        "# Importing libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FYB6UoFHQAt"
      },
      "outputs": [],
      "source": [
        "# Import the libraries we'll use below.\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.patches as mpatches\n",
        "import pandas as pd\n",
        "import seaborn as sns \n",
        "sns.set(style=\"darkgrid\") \n",
        "import plotly.graph_objs as plotly  \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "\n",
        "#setting  seed\n",
        "np.random.seed(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwGe-k6-zDRt"
      },
      "source": [
        "# Section 1: Importing data\n",
        "\n",
        "Our main data source is the US Securities Exchange Commission (SEC), Genderize.io, Yahoo Finance. The data are not processed. \n",
        "\n",
        "The features included year, Total (which denotes total compensation: a summation of salary, stock awards, option awards, non-equity incentive compensation and other compensation), Market Cap (stock price * shares outstanding), last and first names, sector (such a technology) and industry (a further classification of sector). \n",
        "\n",
        "The original data frame consists of 293,504 rows and 19 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq9g-aYHwktv"
      },
      "source": [
        "# Section 2: Feature engineering\n",
        "\n",
        "The data required a great deal of cleaning. We noted several issues, including non-sensical values; for example, market capitilization, which is the price of the stock times the shares outstanding was -1 in some rows(impossible) or zero. We filtered the dataframe to remove any irrelevant values.\n",
        "\n",
        "We also catergorized C-suite job titles and produced bins for salary ranges (which were extremely wide). We binarized male/females.  Lastly, we normalized data for market cap and total compensation. \n",
        "\n",
        "After cleaning, the dataframe has 18,081 rows and 24 features. There is a large skew towards men (85% of the rows) and thus we rebalance the data to be a 50/50 split.  After the rebalancing, the training and test dataframe has 2,662 rows each. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72FdqE7Wzu4j"
      },
      "source": [
        "# Section 3: Exploratory Data Analysis\n",
        "\n",
        "\n",
        "Some findings from EDA:\n",
        " \n",
        "*   US executives of large publicly-traded companies have very high total compensation, and the deviations are extremely large.\n",
        "*   Very few women executives earning at the top compensation levels.\n",
        "*  Female CEOs out earn males on average but no female CEOS earning top compensation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bE5LJNVlVQB"
      },
      "source": [
        "### Histograms to analyze data\n",
        "\n",
        "There is a large spread in compensation, ranging from around 250,000 to 100 million. We noted that most of the compensation is clustered around the lower end of compensation and we analyze by select positions, with CEOs male earning the most and with the largest range in compensation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Word Cloud analyze data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Data into training, validation, and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyze split data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XsgIXpeeC6l"
      },
      "source": [
        "# Section 4: Model building and predictions.\n",
        "\n",
        "We build a simple model to start, using 1 feature, gender and one layer (model 1).  We then add on other features and multi layers (model2, model3 and model4). In Model5, we use a one-hot encoding to transform the catergorical variable, sector and run a multi-layer 12 feature model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ek174sGbek"
      },
      "source": [
        "## Model 1: One feature, gender\n",
        "We train a simple model with one feature, gender. We experiment with different learning rates and optimizer and find that learning rate = 0.01 and optimizer Adam has the lowest loss and validation loss and best convergence. Our model predicts that males have higher compensation than females (1.6 million  vs 1.4 million, respectively). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEv-Ps2y411i"
      },
      "source": [
        "## Tuning Hyperparameters\n",
        "\n",
        "We experiment with different optimizers and learning rates.  We find that Adam optimizer plus learning rate of 0.01 has the best convergence of the loss and validation loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU-f8E67qYk-"
      },
      "source": [
        "Model | Optimizer | Learning rate | Loss | Val Loss\n",
        "-|-|-|-|-|\n",
        "Model 1: Gender|SGD|0.01|0.046|0.049|\n",
        "Model 1: Gender|SGD|0.001|0.700|1.344|\n",
        "Model 1: Gender|SGD|0.0001|1.476|2.801|\n",
        "Model 1: Gender|Adam|0.01|0.0359|0.0362|\n",
        "Model 1: Gender|Adam|0.001|1.038|1.934|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQyaqSWii60J"
      },
      "source": [
        "## Model 2: \n",
        "\n",
        "We used a "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCrqrnSMfz3V"
      },
      "source": [
        "## Model 3: \n",
        "\n",
        "We used a \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ9U0op4HH0d"
      },
      "source": [
        "## Model 4: \n",
        "\n",
        "We"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HfoVMupg_71"
      },
      "source": [
        "## Model 5: Multi-layer neutral network, using catergorical data, transformed with one-hot encoding.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 5: Conlusion / Comparing Models. \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
